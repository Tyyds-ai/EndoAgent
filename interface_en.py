import os
import re
import numpy as np
import gradio as gr
from pathlib import Path
import time
import shutil
from dotenv import load_dotenv
from typing import AsyncGenerator, List, Optional, Tuple
from gradio import ChatMessage

# æ·»åŠ é¢„è®¾å›¾åƒçš„è·¯å¾„å¸¸é‡ï¼ˆä½¿ç”¨æ‚¨æŒ‡å®šçš„è·¯å¾„ï¼‰
EXAMPLE_IMAGES_DIR = Path("/path/to/EndoAgent/demo/endoscopy")
os.makedirs(EXAMPLE_IMAGES_DIR, exist_ok=True)

load_dotenv()

class ChatInterface:
    """
    A chat interface for interacting with a medical AI agent through Gradio.

    Handles file uploads, message processing, and chat history management.
    Supports both regular image files and DICOM medical imaging files.
    """

    def __init__(self, agent, tools_dict):
        """
        Initialize the chat interface.

        Args:
            agent: The medical AI agent to handle requests
            tools_dict (dict): Dictionary of available tools for image processing
        """
        self.agent = agent
        self.tools_dict = tools_dict
        self.upload_dir = Path("temp")
        self.upload_dir.mkdir(exist_ok=True)
        self.current_thread_id = None
        # Separate storage for original and display paths
        self.original_file_path = None  # For LLM (.dcm or other)
        self.display_file_path = None  # For UI (always viewable format)

    def handle_upload(self, file_path: str) -> str:
        """
        Handle new file upload and set appropriate paths.

        Args:
            file_path (str): Path to the uploaded file

        Returns:
            str: Display path for UI, or None if no file uploaded
        """
        if not file_path:
            return None

        source = Path(file_path)
        timestamp = int(time.time())

        # Save original file with proper suffix
        suffix = source.suffix.lower()
        saved_path = self.upload_dir / f"upload_{timestamp}{suffix}"
        shutil.copy2(file_path, saved_path)  # Use file_path directly instead of source
        self.original_file_path = str(saved_path)

        # Handle DICOM conversion for display only
        if suffix == ".dcm":
            output, _ = self.tools_dict["DicomProcessorTool"]._run(str(saved_path))
            self.display_file_path = output["image_path"]
        else:
            self.display_file_path = str(saved_path)

        return self.display_file_path

    def add_message(
        self, message: str, display_image: str, history: List[dict]
    ) -> Tuple[List[dict], gr.Textbox]:
        """
        Add a new message to the chat history.

        Args:
            message (str): Text message to add
            display_image (str): Path to image being displayed
            history (List[dict]): Current chat history

        Returns:
            Tuple[List[dict], gr.Textbox]: Updated history and textbox component
        """
        # æ·»åŠ è°ƒè¯•è¾“å‡º
        print(f"æ”¶åˆ°æ¶ˆæ¯: '{message}', å›¾åƒè·¯å¾„: '{display_image}'")
        print(f"å†å²è®°å½•é¡¹æ•°: {len(history) if history else 0}")

        image_path = self.original_file_path or display_image

        if image_path is not None:
            print(f"æ·»åŠ å›¾åƒè·¯å¾„: {image_path}")
            history.append({"role": "user", "content": {"path": image_path}})
        if message is not None:
            print(f"æ·»åŠ æ–‡æœ¬æ¶ˆæ¯: {message}")
            history.append({"role": "user", "content": message})

        return history, gr.Textbox(value=message, interactive=False)

    async def process_message(
        self, message: str, display_image: Optional[str], chat_history: List[ChatMessage]
    ) -> AsyncGenerator[Tuple[List[ChatMessage], Optional[str], str], None]:
        """
        Process a message and generate responses.

        Args:
            message (str): User message to process
            display_image (Optional[str]): Path to currently displayed image
            chat_history (List[ChatMessage]): Current chat history

        Yields:
            Tuple[List[ChatMessage], Optional[str], str]: Updated chat history, display path, and empty string
        """
        # æ·»åŠ è°ƒè¯•è¾“å‡º
        print(f"å¼€å§‹å¤„ç†æ¶ˆæ¯: '{message}'")
        print(f"å½“å‰èŠå¤©å†å²è®°å½•æ•°: {len(chat_history) if chat_history else 0}")

        chat_history = chat_history or []

        # åˆå§‹åŒ–çº¿ç¨‹
        if not self.current_thread_id:
            self.current_thread_id = str(time.time())
            print(f"åˆ›å»ºæ–°çº¿ç¨‹ID: {self.current_thread_id}")

        # æ„å»ºæ¶ˆæ¯æ•°ç»„
        messages = []
        image_path = self.original_file_path or display_image
        if image_path is not None:
            print(f"å›¾åƒè·¯å¾„: {image_path}")
            messages.append({"role": "user", "content": f"path: {image_path}"})
        if message is not None:
            print(f"æ–‡æœ¬æ¶ˆæ¯: {message}")
            messages.append({"role": "user", "content": message})

        # æ·»åŠ å¤„ç†ä¸­æç¤º
        chat_history.append(ChatMessage(role="assistant", content="æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚..."))
        yield chat_history, self.display_file_path, ""

        # ç§»é™¤"å¤„ç†ä¸­"æ¶ˆæ¯
        chat_history.pop()

        print(f"å‡†å¤‡è°ƒç”¨å·¥ä½œæµï¼Œå‘é€ {len(messages)} æ¡æ¶ˆæ¯")

        try:
            for event in self.agent.workflow.stream(
                {"messages": messages}, {"configurable": {"thread_id": self.current_thread_id}}
            ):
                if isinstance(event, dict):
                    if "process" in event:
                        content = event["process"]["messages"][-1].content
                        if content:
                            content = re.sub(r"temp/[^\s]*", "", content)
                            chat_history.append(ChatMessage(role="assistant", content=content))
                            yield chat_history, self.display_file_path, ""

                    elif "execute" in event:
                        for message in event["execute"]["messages"]:
                            tool_name = message.name
                            content = eval(message.content)
                            # åˆ¤æ–­æ˜¯å¦æ˜¯å…ƒç»„è¿”å›å€¼ï¼ˆåƒåˆ†ç±»å·¥å…·ï¼‰æˆ–å•ä¸€å­—å…¸ï¼ˆåƒVQAå·¥å…·ï¼‰
                            if isinstance(content, tuple) and len(content) > 0:
                                tool_result = content[0]
                            else:
                                tool_result = content
                            
                            print(f"å·¥å…·æ‰§è¡Œç»“æœ: {tool_name} - {tool_result}")
                            
                            # æ£€æŸ¥å·¥å…·æ‰§è¡Œæ˜¯å¦å‡ºé”™
                            if isinstance(tool_result, dict) and "error" in tool_result:
                                error_msg = tool_result.get("error", "æœªçŸ¥é”™è¯¯")
                                traceback_info = tool_result.get("traceback", "æ— è¯¦ç»†ä¿¡æ¯")
                                print(f"å·¥å…·æ‰§è¡Œé”™è¯¯: {error_msg}")
                                print(f"é”™è¯¯è¯¦æƒ…: {traceback_info}")
                                
                                chat_history.append(
                                    ChatMessage(
                                        role="assistant",
                                        content=f"âŒ {tool_name} æ‰§è¡Œå¤±è´¥: {error_msg}",
                                        metadata={"title": "Error", "details": traceback_info}
                                    )
                                )
                            elif tool_result:
                                # å¢å¼ºåˆ†å‰²å·¥å…·ç»“æœå¤„ç†
                                # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ†å‰²å·¥å…·ç»“æœä¸”æœ‰å›¾åƒè·¯å¾„
                                if tool_name == "endoscopy_segmentation_tool" and "segmentation_image_path" in tool_result:
                                    # å…ˆæ·»åŠ åˆ†å‰²ç»“æœå›¾åƒ
                                    image_path = tool_result["segmentation_image_path"]
                                    chat_history.append(
                                        ChatMessage(
                                            role="assistant",
                                            content={"path": image_path},
                                        )
                                    )
                                    
                                    # ç„¶åæ·»åŠ åŒ…å«æ ¼å¼æç¤ºçš„æ–‡æœ¬æè¿°
                                    if "description" in tool_result:
                                        description = tool_result["description"]
                                        segment_type = tool_result.get("segmentation_type", "ç—…å˜")
                                        
                                        formatted_text = (
                                            f"å†…çª¥é•œåˆ†å‰²åˆ†æç»“æœ:\n\n"
                                            f"{description}\n\n"
                                            f"æ£€æµ‹ç±»å‹: {segment_type}\n"
                                            f"ç—…å˜åŒºåŸŸç™¾åˆ†æ¯”: {tool_result['lesion_area_percentage']:.2f}%\n"
                                            f"æ£€æµ‹åˆ°çš„ç—…å˜æ•°é‡: {tool_result['num_lesions']}\n\n"
                                            f"[å›¾åƒå·²è‡ªåŠ¨æ˜¾ç¤ºï¼Œæ— éœ€æ’å…¥Markdownå›¾åƒé“¾æ¥]"  # æ·»åŠ è¿™ä¸ªæç¤º
                                        )
                                        
                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content=formatted_text,
                                                metadata={"title": f"ğŸ–¼ï¸ åˆ†å‰²åˆ†æç»“æœ"},
                                            )
                                        )
                                # æ·»åŠ æ£€æµ‹å·¥å…·ç»“æœå¤„ç†
                                elif tool_name == "endoscopy_detection_tool" and "detection_image_path" in tool_result:
                                    # å…ˆæ·»åŠ æ£€æµ‹ç»“æœå›¾åƒ
                                    image_path = tool_result["detection_image_path"]
                                    if image_path:
                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content={"path": image_path},
                                            )
                                        )

                                    # ç„¶åæ·»åŠ æ£€æµ‹ç»“æœæè¿°
                                    if "description" in tool_result:
                                        description = tool_result["description"]
                                        objects_detected = tool_result.get("objects_detected", 0)

                                        formatted_text = (
                                            f"å†…çª¥é•œç—…å˜æ£€æµ‹ç»“æœ:\n\n"
                                            f"{description}\n\n"
                                            f"æ£€æµ‹ä½¿ç”¨çš„ç½®ä¿¡åº¦é˜ˆå€¼: {tool_result.get('confidence', 0.35):.2f}\n"
                                            f"[å›¾åƒå·²è‡ªåŠ¨æ˜¾ç¤ºï¼Œæ— éœ€æ’å…¥Markdownå›¾åƒé“¾æ¥]"
                                        )

                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content=formatted_text,
                                                metadata={"title": f"ğŸ–¼ï¸ æ£€æµ‹åˆ†æç»“æœ ({objects_detected}ä¸ªç›®æ ‡)"},
                                            )
                                        )
                                # æ·»åŠ ç”Ÿæˆå·¥å…·ç»“æœå¤„ç†
                                elif tool_name == "endoscopy_generation_tool" and "generation_image_path" in tool_result:
                                    # å…ˆæ·»åŠ ç”Ÿæˆç»“æœå›¾åƒ
                                    image_path = tool_result["generation_image_path"]
                                    chat_history.append(
                                        ChatMessage(
                                            role="assistant",
                                            content={"path": image_path},
                                        )
                                    )
                                    
                                    # ç„¶åæ·»åŠ æ©ç å›¾åƒ(å¯é€‰)
                                    if "mask_image_path" in tool_result:
                                        mask_path = tool_result["mask_image_path"]
                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content={"path": mask_path},
                                                metadata={"title": "æ¯è‚‰ç”Ÿæˆæ©ç "}
                                            )
                                        )
                                    
                                    # æœ€åæ·»åŠ åŒ…å«æ ¼å¼æç¤ºçš„æ–‡æœ¬æè¿°
                                    if "description" in tool_result:
                                        description = tool_result["description"]
                                        formatted_text = (
                                            f"å†…çª¥é•œæ¯è‚‰ç”Ÿæˆç»“æœ:\n\n"
                                            f"{description}\n\n"
                                            f"ç”Ÿæˆæç¤ºè¯: {tool_result['prompt']}\n"
                                            f"ç”Ÿæˆæ­¥æ•°: {tool_result['steps']}\n\n"
                                            f"[å›¾åƒå·²è‡ªåŠ¨æ˜¾ç¤ºï¼Œæ— éœ€æ’å…¥Markdownå›¾åƒé“¾æ¥]"
                                        )
                                        
                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content=formatted_text,
                                                metadata={"title": f"ğŸ–¼ï¸ æ¯è‚‰ç”Ÿæˆç»“æœ"},
                                            )
                                        )
                                # æ·»åŠ VQAå·¥å…·ç»“æœå¤„ç†
                                elif tool_name == "endoscopy_vqa_tool" and isinstance(tool_result, dict):
                                    if "error" in tool_result:
                                        error_msg = tool_result.get("error", "æœªçŸ¥é”™è¯¯")
                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content=f"âŒ VQAåˆ†æå¤±è´¥: {error_msg}",
                                                metadata={"title": "é”™è¯¯"}
                                            )
                                        )
                                    else:
                                        # è·å–VQAç»“æœ
                                        response = tool_result.get("result", 
                                                     tool_result.get("description", "æ— æ³•è·å–åˆ†æç»“æœ"))
                                        question = tool_result.get("question", "")
                                        
                                        # æ ¼å¼åŒ–VQAå›ç­”
                                        formatted_text = (
                                            f"å†…çª¥é•œå›¾åƒåˆ†æç»“æœ:\n\n"
                                            f"{response}\n\n"
                                        )
                                        
                                        if question:
                                            formatted_text += f"åˆ†æé—®é¢˜: {question}\n"
                                        
                                        # æ·»åŠ åˆ°èŠå¤©å†å²
                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content=formatted_text,
                                                metadata={"title": "ğŸ” å›¾åƒé—®ç­”åˆ†æ"}
                                            )
                                        )
                                elif tool_name == "endoscopy_report_generator_tool" and "report" in tool_result:
                                    report_text = tool_result["report"]
                                    
                                    # æ·»åŠ æŠ¥å‘Šåˆ°èŠå¤©å†å²
                                    chat_history.append(
                                        ChatMessage(
                                            role="assistant",
                                            content=report_text,
                                            metadata={"title": "ğŸ“‹ å†…çª¥é•œæ£€æŸ¥æŠ¥å‘Š"}
                                        )
                                    )
                                # å¸¸è§„å·¥å…·ç»“æœå¤„ç†    
                                else:
                                    metadata = {"title": f"ğŸ–¼ï¸ Image from tool: {tool_name}"}
                                    formatted_result = " ".join(
                                        line.strip() for line in str(tool_result).splitlines()
                                    ).strip()
                                    metadata["description"] = formatted_result
                                    chat_history.append(
                                        ChatMessage(
                                            role="assistant",
                                            content=formatted_result,
                                            metadata=metadata,
                                        )
                                    )
                    
                                # For image_visualizer, use display path
                                if tool_name == "image_visualizer":
                                    self.display_file_path = tool_result["image_path"]
                                    chat_history.append(
                                        ChatMessage(
                                            role="assistant",
                                            # content=gr.Image(value=self.display_file_path),
                                            content={"path": self.display_file_path},
                                        )
                                    )
                    
                                yield chat_history, self.display_file_path, ""
        except Exception as e:
            chat_history.append(
                ChatMessage(
                    role="assistant", content=f"âŒ Error: {str(e)}", metadata={"title": "Error"}
                )
            )
            yield chat_history, self.display_file_path, ""


def create_demo(agent, tools_dict):
    """
    Create a Gradio demo interface for the medical AI agent.

    Args:
        agent: The medical AI agent to handle requests
        tools_dict (dict): Dictionary of available tools for image processing

    Returns:
        gr.Blocks: Gradio Blocks interface
    """
    print("Creating Gradio demo interface")
    interface = ChatInterface(agent, tools_dict)

    # Define medical endoscopy theme colors
    theme = gr.themes.Soft(
        primary_hue="teal",     # Endoscopy medical green tone
        secondary_hue="blue",   # Medical blue as secondary color
        neutral_hue="slate"     # Gray neutral tone for professional look
    )

    with gr.Blocks(theme=theme) as demo:
        with gr.Column():
            gr.Markdown(
                """
                # ğŸ”¬ EndoAgent - Endoscopy Intelligent Assistant
                ## Endoscopic Image Analysis & Report Generation System

                *Supporting lesion detection, lesion segmentation, lesion classification, endoscopic image analysis, endoscopic image generation, and report generation.*
                """
            )

            with gr.Row():
                # Left side chat area
                with gr.Column(scale=3):
                    chatbot = gr.Chatbot(
                        [],
                        height=700,
                        container=True,
                        show_label=True,
                        elem_classes="chat-box",
                        type="messages",
                        label="Endoscopy Analysis Assistant",
                        avatar_images=(
                            None,
                            "assets/endoagent_logo.png",
                        ),
                    )
                    with gr.Row():
                        with gr.Column(scale=4):
                            txt = gr.Textbox(
                                show_label=False,
                                placeholder="Enter instructions, e.g.: analyze this endoscopy image, detect lesions, generate report...",
                                container=False,
                                lines=2
                            )
                        with gr.Column(scale=1, min_width=100):
                            send_btn = gr.Button("Send ğŸ“¤", variant="primary")

                    # Quick command buttons
                    with gr.Row():
                        gr.Markdown("### Quick Commands")
                    
                    # First row: Image analysis and lesion classification
                    with gr.Row():
                        analyze_btn = gr.Button("ğŸ“Š Analyze Image", size="sm", scale=1)
                        classify_btn = gr.Button("ğŸ·ï¸ Classify Lesion", size="sm", scale=1)
                    
                    # Second row: Detect and segment lesions
                    with gr.Row():
                        detect_btn = gr.Button("ğŸ” Detect Lesions", size="sm", scale=1)
                        segment_btn = gr.Button("âœ‚ï¸ Segment Lesion", size="sm", scale=1)
                    
                    # Third row: Generate polyp and remove polyp
                    with gr.Row():
                        generate_polyp_btn = gr.Button("ğŸš¨ Generate Polyp", size="sm", scale=1)
                        generate_normal_btn = gr.Button("ğŸ›¡ï¸ Remove Polyp", size="sm", scale=1)

                    # Fourth row: Generate report (occupying entire row) 
                    with gr.Row():
                        report_btn = gr.Button("ğŸ“ Generate Report", size="sm", scale=2)

                # Right side image area
                with gr.Column(scale=3):
                    image_display = gr.Image(
                        label="Endoscopy Image",
                        type="filepath", 
                        height=550, 
                        container=True,
                    )
                    
                    # Image upload area
                    with gr.Row():
                        upload_button = gr.UploadButton(
                            "ğŸ“· Upload Endoscopy Image",
                            file_types=["image"],
                            variant="primary"
                        )
                        # dicom_upload = gr.UploadButton(
                            # "ğŸ“„ Upload DICOM File",
                            # file_types=["file"],
                        # )
                        
                    # Status and control area
                    with gr.Row():
                        clear_btn = gr.Button("ğŸ§¹ Clear Chat")
                        new_thread_btn = gr.Button("ğŸ”„ New Session")

                    # Add system information area
                    with gr.Row():
                        gr.Markdown(
                            """
                            ### System Information
                            * Supports common endoscopy image formats: JPG, PNG
                            * Features: lesion detection, lesion segmentation, lesion classification, lesion analysis, image generation, and report generation
                            * Classification categories: normal, hyperplastic, adenomatous, and malignant lesions
                            * AI assists diagnosis; final diagnosis should rely on physician judgment
                            """
                        )

        # Event handlers - keep original logic
        def clear_chat():
            interface.original_file_path = None
            interface.display_file_path = None
            return [], None

        def new_thread():
            interface.current_thread_id = str(time.time())
            return [], interface.display_file_path

        def handle_file_upload(file):
            return interface.handle_upload(file.name)

        # Quick button functionality implementation
        def set_analyze_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "vqa.png")
            return "Please analyze the visible features and structures in this endoscopy image", image_path if os.path.exists(image_path) else None
                    
        def set_classify_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "classify.jpg")
            return "Please classify the lesion in this endoscopy image", image_path if os.path.exists(image_path) else None
                    
        def set_detect_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "detect.jpg") 
            return "Detect lesions in this endoscopy image", image_path if os.path.exists(image_path) else None
                    
        def set_segment_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "segment.jpg")
            return "Segment the lesion in this endoscopy image", image_path if os.path.exists(image_path) else None

        def set_generate_polyp_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "generate_polyp.jpg")
            return "Generate a realistic lesion in this endoscopy image", image_path if os.path.exists(image_path) else None
                    
        def set_generate_normal_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "generate_normal.jpg")
            return "Remove the lesion from this endoscopy image and generate a normal tissue image", image_path if os.path.exists(image_path) else None

        def set_report_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "mrg.jpg")
            return "Generate a detailed report based on the analysis of this endoscopy image", image_path if os.path.exists(image_path) else None
    
        def load_preset(prompt, image_path):
            """å¤„ç†é¢„è®¾çš„æç¤ºè¯å’Œå›¾åƒè·¯å¾„"""
            display_path = None
            if image_path and os.path.exists(image_path):
                # å°†å›¾åƒå¤åˆ¶åˆ°ä¸´æ—¶ç›®å½•ä½¿å…¶å¯ç”¨
                temp_dir = Path("temp")
                temp_dir.mkdir(exist_ok=True)
                timestamp = int(time.time())
                filename = f"preset_{timestamp}{Path(image_path).suffix}"
                saved_path = temp_dir / filename
                shutil.copy2(image_path, saved_path)
                display_path = str(saved_path)
                
                # è®¾ç½®ä¸ºåŸå§‹æ–‡ä»¶è·¯å¾„ï¼Œè¿™æ ·å…¶ä»–å·¥å…·å¯ä»¥ä½¿ç”¨
                interface.original_file_path = display_path
                interface.display_file_path = display_path
                
                print(f"å·²åŠ è½½é¢„è®¾å›¾åƒ: {image_path} -> {display_path}")
            else:
                print(f"é¢„è®¾å›¾åƒä¸å­˜åœ¨: {image_path}")
            return prompt, display_path
            
        # Debug function
        def debug_input(message, display_image):
            print(f"Debug - Received message: '{message}'")
            print(f"Debug - Display image: '{display_image}'")
            return message

        # Add debug before binding events
        txt.submit(debug_input, inputs=[txt, image_display], outputs=[])
        send_btn.click(debug_input, inputs=[txt, image_display], outputs=[])

        # Keep the original message processing logic
        chat_msg = txt.submit(
            interface.add_message, inputs=[txt, image_display, chatbot], outputs=[chatbot, txt]
        ).then(
            interface.process_message,
            inputs=[txt, image_display, chatbot],
            outputs=[chatbot, image_display, txt],
        ).then(lambda: gr.Textbox(interactive=True), None, [txt])
        
        # Send button binds to the same processing logic
        send_btn.click(
            interface.add_message, inputs=[txt, image_display, chatbot], outputs=[chatbot, txt]
        ).then(
            interface.process_message,
            inputs=[txt, image_display, chatbot],
            outputs=[chatbot, image_display, txt],
        ).then(lambda: gr.Textbox(interactive=True), None, [txt])

        # Quick button bindings
        analyze_btn.click(set_analyze_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )
        classify_btn.click(set_classify_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )
        detect_btn.click(set_detect_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )
        segment_btn.click(set_segment_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )
        generate_polyp_btn.click(set_generate_polyp_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )
        generate_normal_btn.click(set_generate_normal_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )
        report_btn.click(set_report_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )

        # File upload
        upload_button.upload(handle_file_upload, inputs=upload_button, outputs=image_display)
        # dicom_upload.upload(handle_file_upload, inputs=dicom_upload, outputs=image_display)

        # Clear and new session
        clear_btn.click(clear_chat, outputs=[chatbot, image_display])
        new_thread_btn.click(new_thread, outputs=[chatbot, image_display])

    return demo