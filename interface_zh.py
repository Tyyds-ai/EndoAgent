import os
import re
import numpy as np
import gradio as gr
from pathlib import Path
import time
import shutil
from dotenv import load_dotenv
from typing import AsyncGenerator, List, Optional, Tuple
from gradio import ChatMessage
from endoagent.tools.enhancer import ResultEnhancer

# æ·»åŠ é¢„è®¾å›¾åƒçš„è·¯å¾„å¸¸é‡ï¼ˆä½¿ç”¨æ‚¨æŒ‡å®šçš„è·¯å¾„ï¼‰
EXAMPLE_IMAGES_DIR = Path("demo/endoscopy")
os.makedirs(EXAMPLE_IMAGES_DIR, exist_ok=True)

load_dotenv()

class ChatInterface:
    """
    A chat interface for interacting with a medical AI agent through Gradio.

    Handles file uploads, message processing, and chat history management.
    Supports both regular image files and DICOM medical imaging files.
    """

    def __init__(self, agent, tools_dict, enable_enhancement=True):
        """
        Initialize the chat interface.

        Args:
            agent: The medical AI agent to handle requests
            tools_dict (dict): Dictionary of available tools for image processing
        """
        self.agent = agent
        self.tools_dict = tools_dict
        self.upload_dir = Path("temp")
        self.upload_dir.mkdir(exist_ok=True)
        self.current_thread_id = None
        # Separate storage for original and display paths
        self.original_file_path = None  # For LLM (.dcm or other)
        self.display_file_path = None  # For UI (always viewable format)

        # æ–°å¢ï¼šç»“æœå¢å¼ºåŠŸèƒ½
        self.enable_enhancement = enable_enhancement
        if enable_enhancement:
            self.enhancer = ResultEnhancer()
        
        # æ–°å¢ï¼šè®°å½•å½“å‰ä¼šè¯ä¿¡æ¯
        self.current_question = ""  # å½“å‰é—®é¢˜
        self.current_tool_outputs = []  # å½“å‰å¯¹è¯ä¸­æ‰€æœ‰å·¥å…·è¾“å‡º
        self.agent_responses = []  # å½“å‰å¯¹è¯ä¸­æ‰€æœ‰Agentå›åº”

    def handle_upload(self, file_path: str) -> str:
        """
        Handle new file upload and set appropriate paths.

        Args:
            file_path (str): Path to the uploaded file

        Returns:
            str: Display path for UI, or None if no file uploaded
        """
        if not file_path:
            return None

        source = Path(file_path)
        timestamp = int(time.time())

        # Save original file with proper suffix
        suffix = source.suffix.lower()
        saved_path = self.upload_dir / f"upload_{timestamp}{suffix}"
        shutil.copy2(file_path, saved_path)  # Use file_path directly instead of source
        self.original_file_path = str(saved_path)

        # Handle DICOM conversion for display only
        if suffix == ".dcm":
            output, _ = self.tools_dict["DicomProcessorTool"]._run(str(saved_path))
            self.display_file_path = output["image_path"]
        else:
            self.display_file_path = str(saved_path)

        return self.display_file_path

    def add_message(
        self, message: str, display_image: str, history: List[dict]
    ) -> Tuple[List[dict], gr.Textbox]:
        """
        Add a new message to the chat history.

        Args:
            message (str): Text message to add
            display_image (str): Path to image being displayed
            history (List[dict]): Current chat history

        Returns:
            Tuple[List[dict], gr.Textbox]: Updated history and textbox component
        """
        # æ·»åŠ è°ƒè¯•è¾“å‡º
        print(f"æ”¶åˆ°æ¶ˆæ¯: '{message}', å›¾åƒè·¯å¾„: '{display_image}'")
        print(f"å†å²è®°å½•é¡¹æ•°: {len(history) if history else 0}")

        image_path = self.original_file_path or display_image

        if image_path is not None:
            print(f"æ·»åŠ å›¾åƒè·¯å¾„: {image_path}")
            history.append({"role": "user", "content": {"path": image_path}})
        if message is not None:
            print(f"æ·»åŠ æ–‡æœ¬æ¶ˆæ¯: {message}")
            history.append({"role": "user", "content": message})
        # ä¿å­˜å½“å‰é—®é¢˜å’Œé‡ç½®è¾“å‡ºæ”¶é›†
        if message:
            self.current_question = message
            # æ¯æ¬¡æ–°é—®é¢˜æ—¶ï¼Œé‡ç½®æ”¶é›†çš„æ•°æ®
            self.current_tool_outputs = []
            self.agent_responses = []

        return history, gr.Textbox(value=message, interactive=False)

    async def process_message(
        self, message: str, display_image: Optional[str], chat_history: List[ChatMessage]
    ) -> AsyncGenerator[Tuple[List[ChatMessage], Optional[str], str], None]:
        """
        Process a message and generate responses.

        Args:
            message (str): User message to process
            display_image (Optional[str]): Path to currently displayed image
            chat_history (List[ChatMessage]): Current chat history

        Yields:
            Tuple[List[ChatMessage], Optional[str], str]: Updated chat history, display path, and empty string
        """
        # æ·»åŠ è°ƒè¯•è¾“å‡º
        print(f"å¼€å§‹å¤„ç†æ¶ˆæ¯: '{message}'")
        print(f"å½“å‰èŠå¤©å†å²è®°å½•æ•°: {len(chat_history) if chat_history else 0}")

        chat_history = chat_history or []

        # åˆå§‹åŒ–çº¿ç¨‹
        if not self.current_thread_id:
            self.current_thread_id = str(time.time())
            print(f"åˆ›å»ºæ–°çº¿ç¨‹ID: {self.current_thread_id}")

        # æ„å»ºæ¶ˆæ¯æ•°ç»„
        messages = []
        image_path = self.original_file_path or display_image
        if image_path is not None:
            print(f"å›¾åƒè·¯å¾„: {image_path}")
            messages.append({"role": "user", "content": f"path: {image_path}"})
        if message is not None:
            print(f"æ–‡æœ¬æ¶ˆæ¯: {message}")
            messages.append({"role": "user", "content": message})

        # æ·»åŠ å¤„ç†ä¸­æç¤º
        chat_history.append(ChatMessage(role="assistant", content="æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚..."))
        yield chat_history, self.display_file_path, ""

        # ç§»é™¤"å¤„ç†ä¸­"æ¶ˆæ¯
        chat_history.pop()

        print(f"å‡†å¤‡è°ƒç”¨å·¥ä½œæµï¼Œå‘é€ {len(messages)} æ¡æ¶ˆæ¯")

        try:
            for event in self.agent.workflow.stream(
                {"messages": messages}, {"configurable": {"thread_id": self.current_thread_id}}
            ):
                if isinstance(event, dict):
                    if "process" in event:
                        content = event["process"]["messages"][-1].content
                        if content:
                            content = re.sub(r"temp/[^\s]*", "", content)
                            # æ”¶é›†Agentå›åº”
                            self.agent_responses.append(content)
                            chat_history.append(ChatMessage(role="assistant", content=content))
                            yield chat_history, self.display_file_path, ""

                    elif "execute" in event:
                        for message in event["execute"]["messages"]:
                            tool_name = message.name
                            content = eval(message.content)
                            # åˆ¤æ–­æ˜¯å¦æ˜¯å…ƒç»„è¿”å›å€¼
                            if isinstance(content, tuple) and len(content) > 0:
                                tool_result = content[0]
                            else:
                                tool_result = content
                            
                            # æ”¶é›†å·¥å…·è¾“å‡º
                            self.current_tool_outputs.append({
                                "tool_name": tool_name,
                                "result": tool_result
                            })
                            
                            print(f"å·¥å…·æ‰§è¡Œç»“æœ: {tool_name} - {tool_result}")
                            
                            # æ£€æŸ¥å·¥å…·æ‰§è¡Œæ˜¯å¦å‡ºé”™
                            if isinstance(tool_result, dict) and "error" in tool_result:
                                error_msg = tool_result.get("error", "æœªçŸ¥é”™è¯¯")
                                traceback_info = tool_result.get("traceback", "æ— è¯¦ç»†ä¿¡æ¯")
                                print(f"å·¥å…·æ‰§è¡Œé”™è¯¯: {error_msg}")
                                print(f"é”™è¯¯è¯¦æƒ…: {traceback_info}")
                                
                                chat_history.append(
                                    ChatMessage(
                                        role="assistant",
                                        content=f"âŒ {tool_name} æ‰§è¡Œå¤±è´¥: {error_msg}",
                                        metadata={"title": "Error", "details": traceback_info}
                                    )
                                )
                            elif tool_result:
                                # å¢å¼ºåˆ†å‰²å·¥å…·ç»“æœå¤„ç†
                                # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ†å‰²å·¥å…·ç»“æœä¸”æœ‰å›¾åƒè·¯å¾„
                                if tool_name == "endoscopy_segmentation_tool" and "segmentation_image_path" in tool_result:
                                    # å…ˆæ·»åŠ åˆ†å‰²ç»“æœå›¾åƒ
                                    image_path = tool_result["segmentation_image_path"]
                                    chat_history.append(
                                        ChatMessage(
                                            role="assistant",
                                            content={"path": image_path},
                                        )
                                    )
                                    
                                    # ç„¶åæ·»åŠ åŒ…å«æ ¼å¼æç¤ºçš„æ–‡æœ¬æè¿°
                                    if "description" in tool_result:
                                        description = tool_result["description"]
                                        segment_type = tool_result.get("segmentation_type", "ç—…å˜")
                                        
                                        formatted_text = (
                                            f"å†…çª¥é•œåˆ†å‰²åˆ†æç»“æœ:\n\n"
                                            f"{description}\n\n"
                                            f"æ£€æµ‹ç±»å‹: {segment_type}\n"
                                            f"ç—…å˜åŒºåŸŸç™¾åˆ†æ¯”: {tool_result['lesion_area_percentage']:.2f}%\n"
                                            f"æ£€æµ‹åˆ°çš„ç—…å˜æ•°é‡: {tool_result['num_lesions']}\n\n"
                                            f"[å›¾åƒå·²è‡ªåŠ¨æ˜¾ç¤ºï¼Œæ— éœ€æ’å…¥Markdownå›¾åƒé“¾æ¥]"  # æ·»åŠ è¿™ä¸ªæç¤º
                                        )
                                        
                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content=formatted_text,
                                                metadata={"title": f"ğŸ–¼ï¸ åˆ†å‰²åˆ†æç»“æœ"},
                                            )
                                        )
                                # æ·»åŠ æ£€æµ‹å·¥å…·ç»“æœå¤„ç†
                                elif tool_name == "endoscopy_detection_tool" and "detection_image_path" in tool_result:
                                    # å…ˆæ·»åŠ æ£€æµ‹ç»“æœå›¾åƒ
                                    image_path = tool_result["detection_image_path"]
                                    if image_path:
                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content={"path": image_path},
                                            )
                                        )

                                    # ç„¶åæ·»åŠ æ£€æµ‹ç»“æœæè¿°
                                    if "description" in tool_result:
                                        description = tool_result["description"]
                                        objects_detected = tool_result.get("objects_detected", 0)

                                        formatted_text = (
                                            f"å†…çª¥é•œç—…å˜æ£€æµ‹ç»“æœ:\n\n"
                                            f"{description}\n\n"
                                            f"æ£€æµ‹ä½¿ç”¨çš„ç½®ä¿¡åº¦é˜ˆå€¼: {tool_result.get('confidence', 0.35):.2f}\n"
                                            f"[å›¾åƒå·²è‡ªåŠ¨æ˜¾ç¤ºï¼Œæ— éœ€æ’å…¥Markdownå›¾åƒé“¾æ¥]"
                                        )

                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content=formatted_text,
                                                metadata={"title": f"ğŸ–¼ï¸ æ£€æµ‹åˆ†æç»“æœ ({objects_detected}ä¸ªç›®æ ‡)"},
                                            )
                                        )
                                # æ·»åŠ ç”Ÿæˆå·¥å…·ç»“æœå¤„ç†
                                elif tool_name == "endoscopy_generation_tool" and "generation_image_path" in tool_result:
                                    # å…ˆæ·»åŠ ç”Ÿæˆç»“æœå›¾åƒ
                                    image_path = tool_result["generation_image_path"]
                                    chat_history.append(
                                        ChatMessage(
                                            role="assistant",
                                            content={"path": image_path},
                                        )
                                    )
                                    
                                    # ç„¶åæ·»åŠ æ©ç å›¾åƒ(å¯é€‰)
                                    if "mask_image_path" in tool_result:
                                        mask_path = tool_result["mask_image_path"]
                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content={"path": mask_path},
                                                metadata={"title": "æ¯è‚‰ç”Ÿæˆæ©ç "}
                                            )
                                        )
                                    
                                    # æœ€åæ·»åŠ åŒ…å«æ ¼å¼æç¤ºçš„æ–‡æœ¬æè¿°
                                    if "description" in tool_result:
                                        description = tool_result["description"]
                                        formatted_text = (
                                            f"å†…çª¥é•œæ¯è‚‰ç”Ÿæˆç»“æœ:\n\n"
                                            f"{description}\n\n"
                                            f"ç”Ÿæˆæç¤ºè¯: {tool_result['prompt']}\n"
                                            f"ç”Ÿæˆæ­¥æ•°: {tool_result['steps']}\n\n"
                                            f"[å›¾åƒå·²è‡ªåŠ¨æ˜¾ç¤ºï¼Œæ— éœ€æ’å…¥Markdownå›¾åƒé“¾æ¥]"
                                        )
                                        
                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content=formatted_text,
                                                metadata={"title": f"ğŸ–¼ï¸ æ¯è‚‰ç”Ÿæˆç»“æœ"},
                                            )
                                        )
                                # æ·»åŠ VQAå·¥å…·ç»“æœå¤„ç†
                                elif tool_name == "endoscopy_vqa_tool" and isinstance(tool_result, dict):
                                    if "error" in tool_result:
                                        error_msg = tool_result.get("error", "æœªçŸ¥é”™è¯¯")
                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content=f"âŒ VQAåˆ†æå¤±è´¥: {error_msg}",
                                                metadata={"title": "é”™è¯¯"}
                                            )
                                        )
                                    else:
                                        # è·å–VQAç»“æœ
                                        response = tool_result.get("result", 
                                                     tool_result.get("description", "æ— æ³•è·å–åˆ†æç»“æœ"))
                                        question = tool_result.get("question", "")
                                        
                                        # æ ¼å¼åŒ–VQAå›ç­”
                                        formatted_text = (
                                            f"å†…çª¥é•œå›¾åƒåˆ†æç»“æœ:\n\n"
                                            f"{response}\n\n"
                                        )
                                        
                                        if question:
                                            formatted_text += f"åˆ†æé—®é¢˜: {question}\n"
                                        
                                        # æ·»åŠ åˆ°èŠå¤©å†å²
                                        chat_history.append(
                                            ChatMessage(
                                                role="assistant",
                                                content=formatted_text,
                                                metadata={"title": "ğŸ” å›¾åƒé—®ç­”åˆ†æ"}
                                            )
                                        )
                                elif tool_name == "endoscopy_report_generator_tool" and "report" in tool_result:
                                    report_text = tool_result["report"]
                                    
                                    # æ·»åŠ æŠ¥å‘Šåˆ°èŠå¤©å†å²
                                    chat_history.append(
                                        ChatMessage(
                                            role="assistant",
                                            content=report_text,
                                            metadata={"title": "ğŸ“‹ å†…çª¥é•œæ£€æŸ¥æŠ¥å‘Š"}
                                        )
                                    )
                                # å¸¸è§„å·¥å…·ç»“æœå¤„ç†    
                                else:
                                    metadata = {"title": f"ğŸ–¼ï¸ Image from tool: {tool_name}"}
                                    formatted_result = " ".join(
                                        line.strip() for line in str(tool_result).splitlines()
                                    ).strip()
                                    metadata["description"] = formatted_result
                                    chat_history.append(
                                        ChatMessage(
                                            role="assistant",
                                            content=formatted_result,
                                            metadata=metadata,
                                        )
                                    )
                    
                                # For image_visualizer, use display path
                                if tool_name == "image_visualizer":
                                    self.display_file_path = tool_result["image_path"]
                                    chat_history.append(
                                        ChatMessage(
                                            role="assistant",
                                            # content=gr.Image(value=self.display_file_path),
                                            content={"path": self.display_file_path},
                                        )
                                    )
                    
                                yield chat_history, self.display_file_path, ""

            # æ‰€æœ‰å·¥å…·æ‰§è¡Œå®Œåï¼Œç”Ÿæˆç»¼åˆå¢å¼ºç»“æœ
            if self.enable_enhancement and self.current_tool_outputs:
                # è°ƒç”¨å¢å¼ºå™¨å¤„ç†ç»¼åˆç»“æœ
                enhanced_result = self.enhancer.enhance_all_results(
                    question=self.current_question,
                    image_path=self.original_file_path or display_image,
                    agent_responses=self.agent_responses,
                    tool_outputs=self.current_tool_outputs
                )
                
                # æ·»åŠ åˆ°èŠå¤©è®°å½•
                chat_history.append(
                    ChatMessage(
                        role="assistant",
                        content=enhanced_result,
                        metadata={"title": "âœ¨ å¢å¼ºåˆ†æç»“æœ"}
                    )
                )
                
                yield chat_history, self.display_file_path, ""
        except Exception as e:
            chat_history.append(
                ChatMessage(
                    role="assistant", content=f"âŒ Error: {str(e)}", metadata={"title": "Error"}
                )
            )
            yield chat_history, self.display_file_path, ""


def create_demo(agent, tools_dict, enable_enhancement=True):
    """
    Create a Gradio demo interface for the medical AI agent.

    Args:
        agent: The medical AI agent to handle requests
        tools_dict (dict): Dictionary of available tools for image processing

    Returns:
        gr.Blocks: Gradio Blocks interface
    """
    print("åˆ›å»º Gradio æ¼”ç¤ºç•Œé¢")
    print(f"ç»“æœå¢å¼ºåŠŸèƒ½: {'å·²å¯ç”¨' if enable_enhancement else 'å·²ç¦ç”¨'}")
    interface = ChatInterface(agent, tools_dict, enable_enhancement=enable_enhancement)
    
    # å®šä¹‰åŒ»ç–—å†…çª¥é•œä¸»é¢˜é¢œè‰²
    theme = gr.themes.Soft(
        primary_hue="teal",     # å†…çª¥é•œåŒ»ç–—ç»¿è‰²è°ƒ
        secondary_hue="blue",   # åŒ»ç–—è“è‰²ä½œä¸ºè¾…åŠ©è‰²
        neutral_hue="slate"     # ç°è‰²ä¸­æ€§è‰²è°ƒï¼Œä¸“ä¸šæ„Ÿ
    )

    with gr.Blocks(theme=theme) as demo:
        with gr.Column():
            gr.Markdown(
                """
                # ğŸ”¬ EndoAgent - å†…çª¥é•œæ™ºèƒ½åŠ©æ‰‹
                ## å†…çª¥é•œå›¾åƒåˆ†æä¸æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ
                
                *æ”¯æŒç—…å˜æ£€æµ‹ã€ç—…å˜åˆ†å‰²ã€ç—…å˜åˆ†ç±»ã€å†…çª¥é•œå›¾åƒåˆ†æã€å†…çª¥é•œå›¾åƒç”Ÿæˆå’ŒæŠ¥å‘Šç”Ÿæˆ*
                """
            )

            with gr.Row():
                # å·¦ä¾§èŠå¤©åŒºåŸŸ
                with gr.Column(scale=3):
                    chatbot = gr.Chatbot(
                        [],
                        height=700,
                        container=True,
                        show_label=True,
                        elem_classes="chat-box",
                        type="messages",
                        label="å†…çª¥é•œåˆ†æåŠ©æ‰‹",
                        avatar_images=(
                            None,
                            "assets/endoagent_logo.png",
                        ),
                    )
                    with gr.Row():
                        with gr.Column(scale=4):
                            txt = gr.Textbox(
                                show_label=False,
                                placeholder="è¾“å…¥æŒ‡ä»¤ï¼Œå¦‚ï¼šåˆ†æè¿™å¼ å†…çª¥é•œå›¾åƒã€æ£€æµ‹æ¯è‚‰ã€ç”ŸæˆæŠ¥å‘Š...",
                                container=False,
                                lines=2
                            )
                        with gr.Column(scale=1, min_width=100):
                            send_btn = gr.Button("å‘é€ ğŸ“¤", variant="primary")

                    # å¿«æ·æŒ‡ä»¤æŒ‰é’®
                    with gr.Row():
                        gr.Markdown("### å¿«æ·æŒ‡ä»¤")
                    
                    # ç¬¬ä¸€è¡Œï¼šåˆ†æå›¾åƒå’Œç—…å˜åˆ†ç±»
                    with gr.Row():
                        analyze_btn = gr.Button("ğŸ“Š åˆ†æå›¾åƒ", size="sm", scale=1)
                        classify_btn = gr.Button("ğŸ·ï¸ ç—…å˜åˆ†ç±»", size="sm", scale=1)
                    
                    # ç¬¬äºŒè¡Œï¼šæ£€æµ‹å’Œåˆ†å‰²ç—…å˜
                    with gr.Row():
                        detect_btn = gr.Button("ğŸ” æ£€æµ‹ç—…å˜", size="sm", scale=1)
                        segment_btn = gr.Button("âœ‚ï¸ åˆ†å‰²ç—…å˜", size="sm", scale=1)
                    
                    # ç¬¬ä¸‰è¡Œï¼šç”Ÿæˆæ¯è‚‰å’Œå»é™¤æ¯è‚‰(ç”Ÿæˆæ­£å¸¸)æŒ‰é’®
                    with gr.Row():
                        generate_polyp_btn = gr.Button("ğŸš¨ ç”Ÿæˆæ¯è‚‰", size="sm", scale=1)  
                        generate_normal_btn = gr.Button("ğŸ›¡ï¸ å»é™¤æ¯è‚‰", size="sm", scale=1)  
                    
                    # ç¬¬å››è¡Œï¼šç”ŸæˆæŠ¥å‘Šï¼ˆç‹¬å ä¸€è¡Œï¼‰
                    with gr.Row():
                        report_btn = gr.Button("ğŸ“ ç”ŸæˆæŠ¥å‘Š", size="sm", scale=2)

                # å³ä¾§å›¾åƒåŒºåŸŸ
                with gr.Column(scale=3):
                    image_display = gr.Image(
                        label="å†…çª¥é•œå›¾åƒ",
                        type="filepath", 
                        height=550, 
                        container=True,
                    )
                    
                    # å›¾åƒä¸Šä¼ åŒºåŸŸ
                    with gr.Row():
                        upload_button = gr.UploadButton(
                            "ğŸ“· ä¸Šä¼ å†…çª¥é•œå›¾åƒ",
                            file_types=["image"],
                            variant="primary"
                        )
                        # dicom_upload = gr.UploadButton(
                            # "ğŸ“„ ä¸Šä¼ DICOMæ–‡ä»¶",
                            # file_types=["file"],
                        # )
                        
                    # çŠ¶æ€å’Œæ§åˆ¶åŒº
                    with gr.Row():
                        clear_btn = gr.Button("ğŸ§¹ æ¸…ç©ºå¯¹è¯")
                        new_thread_btn = gr.Button("ğŸ”„ æ–°ä¼šè¯")

                    # æ·»åŠ ç³»ç»Ÿä¿¡æ¯åŒºåŸŸ
                    with gr.Row():
                        gr.Markdown(
                            """
                            ### ç³»ç»Ÿä¿¡æ¯
                            * æ”¯æŒå¸¸è§å†…çª¥é•œå›¾åƒæ ¼å¼ï¼šJPGã€PNG
                            * å¯è¿›è¡Œç—…å˜æ£€æµ‹ã€ç—…å˜åˆ†å‰²ã€ç—…å˜åˆ†ç±»ã€ç—…å˜åˆ†æã€å›¾åƒç”Ÿæˆä¸æŠ¥å‘Šç”Ÿæˆ
                            * ç—…å˜åˆ†ç±»æ”¯æŒï¼šæ­£å¸¸ã€å¢ç”Ÿæ€§ã€è…ºç˜¤æ€§ä¸æ¶æ€§ç—…å˜
                            * ä½¿ç”¨ AI è¾…åŠ©è¯Šæ–­ï¼Œæœ€ç»ˆè¯Šæ–­è¯·ä»¥åŒ»ç”Ÿåˆ¤æ–­ä¸ºå‡†
                            """
                        )

        # Event handlers - ä¿ç•™åŸæœ‰é€»è¾‘
        def clear_chat():
            interface.original_file_path = None
            interface.display_file_path = None
            return [], None

        def new_thread():
            interface.current_thread_id = str(time.time())
            return [], interface.display_file_path

        def handle_file_upload(file):
            return interface.handle_upload(file.name)

        # å¿«æ·æŒ‰é’®åŠŸèƒ½å®ç°
        def set_analyze_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "vqa.png")
            return "è¯·åˆ†æè¿™å¼ å†…çª¥é•œå›¾åƒä¸­å¯è§çš„ç‰¹å¾å’Œç»“æ„", image_path if os.path.exists(image_path) else None
                    
        def set_classify_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "classify.jpg")
            return "å¯¹è¿™å¼ å†…çª¥é•œå›¾åƒè¿›è¡Œç—…å˜åˆ†ç±»", image_path if os.path.exists(image_path) else None
                    
        def set_detect_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "detect.jpg") 
            return "æ£€æµ‹è¿™å¼ å†…çª¥é•œå›¾åƒä¸­çš„ç—…å˜", image_path if os.path.exists(image_path) else None
                    
        def set_segment_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "segment.jpg")
            return "å¯¹è¿™å¼ å†…çª¥é•œå›¾åƒè¿›è¡Œç—…å˜åˆ†å‰²", image_path if os.path.exists(image_path) else None
        
        def set_generate_polyp_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "generate_polyp.jpg")
            return "è¯·åœ¨è¿™å¼ å†…çª¥é•œå›¾åƒä¸­ç”Ÿæˆä¸€ä¸ªé€¼çœŸçš„ç—…å˜", image_path if os.path.exists(image_path) else None
                    
        def set_generate_normal_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "generate_normal.jpg")
            return "è¯·å°†è¿™å¼ å†…çª¥é•œå›¾åƒä¸­çš„ç—…å˜å»é™¤ï¼Œç”Ÿæˆä¸€å¼ æ­£å¸¸çš„å›¾åƒ", image_path if os.path.exists(image_path) else None
        
        def set_report_prompt():
            image_path = str(EXAMPLE_IMAGES_DIR / "mrg.jpg")
            return "å¸®æˆ‘ç”Ÿæˆä¸€ä»½å†…çª¥é•œæ£€æŸ¥æŠ¥å‘Šï¼Œæè¿°å›¾åƒä¸­çš„ç—…å˜å’Œè§‚å¯Ÿç»“æœ", image_path if os.path.exists(image_path) else None

        # æ·»åŠ å¤„ç†é¢„è®¾å†…å®¹çš„å‡½æ•°
        def load_preset(prompt, image_path):
            """å¤„ç†é¢„è®¾çš„æç¤ºè¯å’Œå›¾åƒè·¯å¾„"""
            display_path = None
            if image_path and os.path.exists(image_path):
                # å°†å›¾åƒå¤åˆ¶åˆ°ä¸´æ—¶ç›®å½•ä½¿å…¶å¯ç”¨
                temp_dir = Path("temp")
                temp_dir.mkdir(exist_ok=True)
                timestamp = int(time.time())
                filename = f"preset_{timestamp}{Path(image_path).suffix}"
                saved_path = temp_dir / filename
                shutil.copy2(image_path, saved_path)
                display_path = str(saved_path)
                
                # è®¾ç½®ä¸ºåŸå§‹æ–‡ä»¶è·¯å¾„ï¼Œè¿™æ ·å…¶ä»–å·¥å…·å¯ä»¥ä½¿ç”¨
                interface.original_file_path = display_path
                interface.display_file_path = display_path
                
                print(f"å·²åŠ è½½é¢„è®¾å›¾åƒ: {image_path} -> {display_path}")
            else:
                print(f"é¢„è®¾å›¾åƒä¸å­˜åœ¨: {image_path}")
            return prompt, display_path
            
        # è°ƒè¯•å‡½æ•°
        def debug_input(message, display_image):
            print(f"è°ƒè¯• - æ”¶åˆ°æ¶ˆæ¯: '{message}'")
            print(f"è°ƒè¯• - æ˜¾ç¤ºå›¾åƒ: '{display_image}'")
            return message

        # ç»‘å®šäº‹ä»¶å‰å…ˆæ·»åŠ è°ƒè¯•
        txt.submit(debug_input, inputs=[txt, image_display], outputs=[])
        send_btn.click(debug_input, inputs=[txt, image_display], outputs=[])

        # åŸæœ‰çš„æ¶ˆæ¯å¤„ç†é€»è¾‘ä¿æŒä¸å˜
        chat_msg = txt.submit(
            interface.add_message, inputs=[txt, image_display, chatbot], outputs=[chatbot, txt]
        ).then(
            interface.process_message,
            inputs=[txt, image_display, chatbot],
            outputs=[chatbot, image_display, txt],
        ).then(lambda: gr.Textbox(interactive=True), None, [txt])
        
        # å‘é€æŒ‰é’®ç»‘å®šç›¸åŒçš„å¤„ç†é€»è¾‘
        send_btn.click(
            interface.add_message, inputs=[txt, image_display, chatbot], outputs=[chatbot, txt]
        ).then(
            interface.process_message,
            inputs=[txt, image_display, chatbot],
            outputs=[chatbot, image_display, txt],
        ).then(lambda: gr.Textbox(interactive=True), None, [txt])

        # å¿«æ·æŒ‰é’®ç»‘å®š
        analyze_btn.click(set_analyze_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )
        classify_btn.click(set_classify_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )
        detect_btn.click(set_detect_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )
        segment_btn.click(set_segment_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )
        generate_polyp_btn.click(set_generate_polyp_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )
        generate_normal_btn.click(set_generate_normal_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )
        report_btn.click(set_report_prompt, outputs=[txt, image_display]).then(
            load_preset, inputs=[txt, image_display], outputs=[txt, image_display]
        )

        # æ–‡ä»¶ä¸Šä¼ 
        upload_button.upload(handle_file_upload, inputs=upload_button, outputs=image_display)
        # dicom_upload.upload(handle_file_upload, inputs=dicom_upload, outputs=image_display)

        # æ¸…ç©ºå’Œæ–°ä¼šè¯
        clear_btn.click(clear_chat, outputs=[chatbot, image_display])
        new_thread_btn.click(new_thread, outputs=[chatbot, image_display])

    return demo