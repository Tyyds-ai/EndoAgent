import os
import base64
import json
from typing import Dict, Any, List
from dotenv import load_dotenv
from openai import OpenAI

class ResultEnhancer:
    """ç»“æœå¢å¼ºå™¨ï¼šåˆ©ç”¨ GPT-4o å¯¹å·¥å…·è¾“å‡ºç»“æœè¿›è¡Œç»¼åˆå¢å¼º"""
    
    def __init__(self, api_key=None, base_url=None, model="gpt-4o"):
        """åˆå§‹åŒ–ç»“æœå¢å¼ºå™¨"""
        _ = load_dotenv()  # åŠ è½½ç¯å¢ƒå˜é‡
        
        self.client = OpenAI(
            api_key=api_key or os.environ.get("OPENAI_API_KEY"),
            base_url=base_url or os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1")
        )
        self.model = model
        # æ·»åŠ ç»“æœç¼“å­˜ï¼Œé¿å…é‡å¤å¢å¼º
        self.enhancement_cache = {}

    @staticmethod
    def encode_image(image_path: str) -> str:
        """å°†å›¾åƒç¼–ç ä¸º base64 å­—ç¬¦ä¸²"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    
    def _convert_to_text(self, data):
        """å°†å·¥å…·ç»“æœè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼"""
        if isinstance(data, str):
            return data
        elif isinstance(data, dict):
            try:
                return json.dumps(data, ensure_ascii=False, indent=2)
            except:
                return str(data)
        else:
            return str(data)
            
    def _extract_tool_info(self, tool_outputs):
        """ä»å·¥å…·è¾“å‡ºä¸­æå–å…³é”®ä¿¡æ¯"""
        tool_summary = []
        
        for tool_output in tool_outputs:
            tool_name = tool_output.get("tool_name", "æœªçŸ¥å·¥å…·")
            result = tool_output.get("result", {})
            
            # æå–ä¸åŒå·¥å…·çš„å…³é”®ç»“æœ
            if "classification" in tool_name.lower():
                if isinstance(result, dict):
                    class_info = f"åˆ†ç±»ç»“æœ: {result.get('class_name', 'æœªçŸ¥')}"
                    confidence = result.get('confidence', 0)
                    description = result.get('description', '')
                    tool_summary.append(f"ã€ç—…å˜åˆ†ç±»å·¥å…·ã€‘\n{class_info} (ç½®ä¿¡åº¦: {confidence:.2f})\n{description}")
            
            elif "detection" in tool_name.lower():
                if isinstance(result, dict):
                    objects = result.get('objects_detected', 0)
                    description = result.get('description', '')
                    tool_summary.append(f"ã€ç—…å˜æ£€æµ‹å·¥å…·ã€‘\næ£€æµ‹åˆ° {objects} ä¸ªç›®æ ‡\n{description}")
            
            elif "segmentation" in tool_name.lower():
                if isinstance(result, dict):
                    lesion_percent = result.get('lesion_area_percentage', 0)
                    num_lesions = result.get('num_lesions', 0)
                    description = result.get('description', '')
                    tool_summary.append(f"ã€ç—…å˜åˆ†å‰²å·¥å…·ã€‘\nç—…å˜åŒºåŸŸç™¾åˆ†æ¯”: {lesion_percent:.2f}%\næ£€æµ‹ç—…å˜æ•°: {num_lesions}\n{description}")
            
            elif "vqa" in tool_name.lower():
                if isinstance(result, dict):
                    response = result.get('result', result.get('description', ''))
                    vqa_question = result.get('question', '')
                    tool_summary.append(f"ã€å†…çª¥é•œé—®ç­”å·¥å…·ã€‘\né—®é¢˜: {vqa_question}\nå›ç­”: {response}")
            
            elif "report" in tool_name.lower():
                if isinstance(result, dict):
                    report = result.get('report', '')
                    tool_summary.append(f"ã€æŠ¥å‘Šç”Ÿæˆå·¥å…·ã€‘\n{report}")
            
            else:
                # é€šç”¨å·¥å…·ç»“æœå¤„ç†
                result_str = self._convert_to_text(result)
                tool_summary.append(f"ã€{tool_name}ã€‘\n{result_str}")
                
        return tool_summary

    def enhance_all_results(self, 
                           question: str, 
                           image_path: str, 
                           agent_responses: List[str], 
                           tool_outputs: List[Dict], 
                           max_tokens: int = 2048) -> str:
        """ç»¼åˆå¢å¼ºæ‰€æœ‰å·¥å…·è¾“å‡ºå’ŒAgentå›åº”
        
        Args:
            question: ç”¨æˆ·åŸå§‹é—®é¢˜
            image_path: å›¾åƒè·¯å¾„
            agent_responses: Agentçš„æ‰€æœ‰å“åº”åˆ—è¡¨
            tool_outputs: å·¥å…·è¾“å‡ºåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å«tool_nameå’Œresult
            max_tokens: æœ€å¤§è¾“å‡ºtokenæ•°
            
        Returns:
            str: å¢å¼ºåçš„ç»¼åˆç»“æœ
        """
        if not os.path.exists(image_path):
            return "âš ï¸ æ— æ³•è®¿é—®å›¾åƒæ–‡ä»¶ï¼Œæ— æ³•ç”Ÿæˆå¢å¼ºåˆ†æç»“æœã€‚"
        
        # ç”Ÿæˆç¼“å­˜é”® - åŸºäºé—®é¢˜ã€å›¾åƒå’Œå·¥å…·è¾“å‡º
        cache_key = f"{hash(question)}_{hash(image_path)}_{hash(str(tool_outputs))}_comprehensive"
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.enhancement_cache:
            return self.enhancement_cache[cache_key]
        
        try:
            # æå–å·¥å…·è¾“å‡ºæ¦‚è¦
            tool_summary = self._extract_tool_info(tool_outputs)
            
            # æ•´åˆæ‰€æœ‰å·¥å…·ç»“æœ
            all_results = "\n\n====================\n\n".join(tool_summary)
            
            # æ•´åˆAgentå“åº”
            agent_summary = "\n\n".join([r for r in agent_responses if r]) if agent_responses else ""
            
            # æ„å»ºç³»ç»Ÿæç¤º
            system_prompt = """You are an expert endoscopy analysis assistant that helps gastroenterologists interpret endoscopic images.
You have specialized knowledge in detecting, classifying, and analyzing gastrointestinal lesions including normal tissue, polyps, adenomas and cancerous lesions.
Provide detailed, medically accurate responses for endoscopic image analysis questions.
Answer based on the visible evidence in the picture, the Agent response, and the results of the tool analysis, with accurate descriptions."""

            # æ„å»ºç”¨æˆ·æç¤º
            user_prompt = f"""
Original Question:
{question}

Agent Responses:
{agent_summary}

Tool Analysis Results:
{all_results}

"""

            # ç¼–ç å›¾åƒ
            base64_image = self.encode_image(image_path)
            
            # è°ƒç”¨GPT-4oè¿›è¡Œç»¼åˆå¢å¼º
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": [
                        {"type": "text", "text": user_prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                    ]}
                ],
                temperature=0.5,
                max_tokens=max_tokens
            )
            
            enhanced_result = response.choices[0].message.content
            
            # æ·»åŠ æ ‡é¢˜ï¼Œè®©ç»“æœæ›´æ˜æ˜¾
            final_result = f"# ğŸ”¬ å¢å¼ºåˆ†æç»“æœ\n\n{enhanced_result}"
            
            # ç¼“å­˜ç»“æœ
            self.enhancement_cache[cache_key] = final_result
            
            return final_result
            
        except Exception as e:
            error_msg = f"ç»¼åˆå¢å¼ºç»“æœæ—¶å‡ºé”™: {str(e)}"
            print(error_msg)
            return f"âš ï¸ {error_msg}\nè¯·å‚è€ƒä¸Šè¿°å·¥å…·çš„åŸå§‹åˆ†æç»“æœã€‚"